{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71e3e304",
   "metadata": {},
   "source": [
    "## Tutoriel de Données du Rover LEAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956daff9",
   "metadata": {},
   "source": [
    "\n",
    "**Tutoriel** : Ce tutoriel consiste en les étapes en Python pour extraire, visualiser et sauvegarder les données *(imagerie, LiDAR)* sous forme de fichiers rosbags capturés par le Rover Juno lors d'une réplication d'une mission lunaire.<br>\n",
    "**Mission et Instrument** : Déploiement Analogique d'Exploration Lunaire (LEAD), Rover Juno <br>\n",
    "**Exigences du système** : Python 3.8.8 <br>\n",
    "**Niveau du tutoriel** : Intermédiaire <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69458199",
   "metadata": {},
   "source": [
    "***\n",
    "**Licence MIT** <br>\n",
    "Copyright (c) Sa Majesté le Roi du chef du Canada, représentée par l'Agence spatiale canadienne, 2023. <br>\n",
    "Droit d'auteur (c) Sa Majesté le Roi du chef du Canada, représentée par l'Agence Spatiale Canadienne, 2023.<br>\n",
    "\n",
    "Pour plus d'informations, veuillez vous référer au fichier *License.txt*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff024cb",
   "metadata": {},
   "source": [
    "***\n",
    " **Informations contextuelles** \n",
    "\n",
    "Entre 2017 et 2019, l'Agence spatiale canadienne (ASC) s'est associée à l'Agence spatiale européenne (ESA) pour mener une série de tests sur le terrain afin de reproduire des scénarios d'une mission de retour d'échantillons lunaires. Ceci était pour acquérir des connaissances et une expérience pratique pour se préparer au prochain chapitre de l'exploration spatiale : envoyer des êtres humains vers des destinations plus lointaines comme la Lune et Mars. <br>\n",
    "\n",
    "Cette simulation de mission a été menée à l'aide du Rover Juno de l'ASC : un rover robuste, tout-terrain. Ces tests sur le terrain ont été effectués en trois phases dans deux endroits : une carrière de pierres et le Terrain Analogique de l'ASC (également connu sous le nom de Mars Yard) au Québec. Le rover était opéré par des équipes basées à Saint-Hubert (Québec) et en Allemagne pour recréer la difficulté des communications longue distance. <br>\n",
    "\n",
    "Ce projet était divisé comme suit : <br>\n",
    "1. **LEAD/HOPE :** Ceci se concentrait sur le fait d'avoir des opérateurs formés effectuer des missions de retour d'échantillons. Cela a eu lieu sur cinq jours en octobre 2017 et quatre jours en juin 2019.\n",
    "2. **Expérience de Collecte de Métriques du Rover LEAD (LRMGE) :** Cette partie de la mission avait six équipes en juin 2019 opérer le rover le long d'un itinéraire prédéfini pour collecter des métriques sur les performances de conduite du rover.\n",
    "3. **Région Perpétuellement Ombragée LEAD (PSR) :** Enfin, cette partie se concentrait sur les tâches de conduite de rover sous des conditions d'éclairage sombre émulant les opérations dans une PSR.\n",
    "\n",
    "L'ensemble de données analysé dans ce tutoriel provient de la phase LEAD (PSR) et a eu lieu en septembre 2019. Il est sous forme de rosbag et fournit l'imagerie, les données LiDAR, et la pose estimée du rover. <br>\n",
    "\n",
    "Vous pouvez lire plus sur la mission ici : <br>\n",
    "**Rover Juno :** https://www.asc-csa.gc.ca/eng/multimedia/search/image/7824<br>\n",
    "**LEAD :** https://www.asc-csa.gc.ca/eng/rovers/mission-simulations/lunar-exploration-analogue-deployment.asp<br>\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;$ https://www.hou.usra.edu/meetings/isairas2020fullpapers/pdf/5015.pdf\n",
    "\n",
    " ***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a797cf08",
   "metadata": {},
   "source": [
    "**Téléchargement de l'ensemble de données :** <br>\n",
    "L'ensemble de données, sous forme de rosbag, peut être téléchargé depuis le Portail de Données Ouvertes : <br>\n",
    "https://donnees-data.asc-csa.gc.ca/dataset/9151430-4v0p-4t5c-468vnhj714ao64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451de1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required imports \n",
    "import imageio.v2 as imageio\n",
    "import os, io, datetime, csv\n",
    "import numpy as np\n",
    "import rosbag, bagpy\n",
    "import pandas as pd \n",
    "import open3d as o3d \n",
    "from sensor_msgs.point_cloud2 import read_points \n",
    "from matplotlib import pyplot as plt \n",
    "import geopandas, folium, base64\n",
    "from folium import IFrame\n",
    "import utm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742f1dd7",
   "metadata": {},
   "source": [
    "***\n",
    "### Ouverture d'un fichier ROSBAG\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24352d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening rosbag file \n",
    "bagpy_bag = bagpy.bagreader('LEAD_delayed_2019-09-25-19-00-01-filtered.bag')\n",
    "bag = rosbag.Bag('LEAD_delayed_2019-09-25-19-00-01-filtered.bag')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00031050",
   "metadata": {},
   "source": [
    ">Jetons un premier coup d'œil au contenu du rosbag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5521a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of topics & types of messages\n",
    "print(bagpy_bag.topic_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba9a866",
   "metadata": {},
   "source": [
    ">Nous commençons par extraire sensor_msgs/CameraInfo et les convertir en fichiers csv. Ceci contient les informations de calibration de caméra de la caméra centrale et gauche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b765cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoding data by topic & converting to dataframe  (Camera Info & Localization)\n",
    "Camera_info_centre_msg = bagpy_bag.message_by_topic('/delayed/artemisJr/centre/camera_info')\n",
    "df_CAMERA_CENTRE = pd.read_csv(Camera_info_centre_msg) #Centre camera calibration\n",
    "\n",
    "Camera_info_left_msg = bagpy_bag.message_by_topic('/delayed/artemisJr/left/camera_info')\n",
    "df_CAMERA_LEFT = pd.read_csv(Camera_info_left_msg) #Left camera calibration\n",
    "\n",
    "df_CAMERA_CENTRE.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e467b2a",
   "metadata": {},
   "source": [
    "*Un aperçu des 5 premières lignes de df_CAMERA_CENTRE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de842527",
   "metadata": {},
   "source": [
    "***\n",
    "### Extraction et visualisation des données de nuage de points (PCD)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e960447",
   "metadata": {},
   "source": [
    "Extrayons maintenant sensor_msgs/PointCloud2 et visualisons-les. Les données de nuage de points 3D proviennent du scanner 3D et sont utilisées pour la navigation (par exemple, évaluation du terrain, planification de parcours). Le nuage de points résultant est voxelisé et les points qui tombent sur le rover sont supprimés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c6234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Point Cloud files from .bag file & converting them to csv files \n",
    "if __name__ == \"__main__\":\n",
    "    path = './csv' #Path for csv folder \n",
    "    if not os.path.exists(path): #Check whether directory already exists, create otherwise\n",
    "        os.mkdir(path)\n",
    "        print(\"Folder %s created!\" % path)\n",
    "    else:\n",
    "        print(\"Folder %s already exists\" % path)\n",
    "        \n",
    "    for msg in bag:\n",
    "        if  msg[0] == \"/delayed/lowrate_scanner/points\":\n",
    "            print(msg[2])\n",
    "            t = datetime.datetime.fromtimestamp(msg[2].to_sec()).strftime(\"%Y-%m-%d-%H_%M_%S\")\n",
    "            name = \"csv/{0}-{1}.csv\".format(msg[0].replace(\"/\",\"_\"),t)\n",
    "            print(\"Saving to \" + name)\n",
    "            with open(name,\"w\") as f:\n",
    "                # Read the points\n",
    "                for point in read_points(msg[1]):\n",
    "                    print(\"{0:.4f}, {1:.4f}, {2:.4f}\".format(point[0],point[1],point[2]), file=f)\n",
    "                f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5c75e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + '\\\\csv'\n",
    "file_list = []\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "            file_list.append(os.path.join(root,file))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349c407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading point cloud data and creating a point cloud object \n",
    "pcd_data = []\n",
    "for file in file_list:\n",
    "        name = file[-54:-4]\n",
    "        data_csv = pd.read_csv(file)\n",
    "        data_array = np.array(data_csv) #Converting to numpy array \n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(data_array)\n",
    "        pcd_data.append(pcd)\n",
    "        o3d.visualization.draw_geometries([pcd])\n",
    "        #o3d.io.write_point_cloud(name + \".pcd\", pcd)  #uncomment to save file \n",
    "        del pcd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9a392c",
   "metadata": {},
   "source": [
    "*Visualisation d'un fichier de nuage de points*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2010ef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imageio.imread(\"1-PCD.png\")\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163fb27e",
   "metadata": {},
   "source": [
    ">Plusieurs autres techniques sont potentiellement utiles dans la visualisation des données de nuages de points. Cela inclut des techniques telles que le développement d'une enveloppe convexe (l'enceinte de tous les points dans un espace), la visualisation de la grille voxel, ou la visualisation d'un octree, toutes montrées ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5092e83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "pcd_dbscan =  pcd_data[i] #update i as needed \n",
    "\n",
    "dist_list = []\n",
    "#Creating a kd-tree for fast retreival of nearest neighbors\n",
    "pcd_tree = o3d.geometry.KDTreeFlann(pcd_dbscan)\n",
    "\n",
    "for i in range(len(np.asarray(pcd_dbscan.points))): \n",
    "    #For each point in the point cloud returns the 3 nearest neighbors distances (4 is used since also returns self)\n",
    "    [k, _, dist] = pcd_tree.search_knn_vector_3d(pcd_dbscan.points[i], 4)\n",
    "\n",
    "    for j in range(1, k):\n",
    "        dist_list.append(dist[j])\n",
    "\n",
    "#Sorting distances\n",
    "dist_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f849e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting graph\n",
    "dist_arr = np.asarray(dist_list)\n",
    "plt.plot(dist_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0fcc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_points = 20\n",
    "eps = 0.1 #from above graph\n",
    "\n",
    "with o3d.utility.VerbosityContextManager(\n",
    "        o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    labels = np.array(\n",
    "        pcd_dbscan.cluster_dbscan(eps = eps, min_points = min_points, print_progress=True)) # dbscan function\n",
    "    \n",
    "max_label = labels.max()\n",
    "\n",
    "# setting a different color for each cluster with no clusters equaling black\n",
    "colors = plt.get_cmap(\"gist_ncar\")(labels / (max_label if max_label > 0 else 1))\n",
    "colors[labels < 0] = 0\n",
    "\n",
    "pcd_dbscan.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "o3d.visualization.draw_geometries([pcd_dbscan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77bd0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing \n",
    "img = imageio.imread(\"2-DBSCAN.png\")\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb097fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other visualizations\n",
    "i = 0\n",
    "pcd_processed = pcd_data[i]\n",
    "\n",
    "pcd_processed.scale(1 / np.max(pcd_data[i].get_max_bound() - pcd_data[i].get_min_bound()), center=pcd_processed.get_center())\n",
    "\n",
    "# assigning a random color to each point in the point cloud \n",
    "pcd_processed.colors = o3d.utility.Vector3dVector(np.random.uniform(0, 1, size=(len(pcd_processed.points), 3)))\n",
    "\n",
    "# determination of the convex hull including edges of the polygon\n",
    "conv_hull, _  = pcd_processed.compute_convex_hull()\n",
    "conv_hull.compute_vertex_normals() # edges\n",
    "o3d.visualization.draw_geometries([conv_hull])\n",
    "\n",
    "# displaying the voxel grid\n",
    "voxel_grid = o3d.geometry.VoxelGrid.create_from_point_cloud(pcd_processed, voxel_size= 0.01) #voxel size correlates to grid\n",
    "o3d.visualization.draw_geometries([voxel_grid])\n",
    "\n",
    "# displaying octree\n",
    "octree = o3d.geometry.Octree(max_depth=4) # depth specifies the level of detailed stored\n",
    "octree.convert_from_point_cloud(pcd_processed, size_expand=0.01)\n",
    "o3d.visualization.draw_geometries([octree])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e2024d",
   "metadata": {},
   "source": [
    "*Le même fichier de nuage de points dans différentes visualisations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd8169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing Point Cloud File \n",
    "fig = plt.figure()\n",
    "Convex_Hull = imageio.imread(\"3-CONVEXHull.png\")\n",
    "Voxel_Grid = imageio.imread(\"4-VOXELGrid.png\")\n",
    "Octree = imageio.imread(\"5-OCTREE.png\")\n",
    "\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "ax1 = fig.add_subplot(1,3,1)\n",
    "plt.axis(\"off\")\n",
    "ax1.imshow(Convex_Hull)\n",
    "ax2 = fig.add_subplot(1,3,2)\n",
    "ax2.imshow(Voxel_Grid)\n",
    "plt.axis(\"off\")\n",
    "ax3 = fig.add_subplot(1,3,3)\n",
    "ax3.imshow(Octree)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab442c5",
   "metadata": {},
   "source": [
    "***\n",
    "### Extraction et visualisation d'images compressées\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf7591c",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant regarder les fichiers restants dans le rosbag qui sont de type sensor_msgs/CompressedImage. Il y a différents sujets dans le sac et vous pouvez remplacer le nom du sujet, selon les images que vous souhaitez extraire. Pour les besoins de ce tutoriel, nous allons extraire et visualiser des images compressées du sujet : */delayed/evo/left_polled/image_rect/compressed.* <br> Chaque message contient une image et un horodatage donc nous allons extraire les deux et les sauvegarder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d47cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list to save images and timestamps of desired topic. \n",
    "Image_Rect_Left_Polled = []\n",
    "Image_Rect_Left_Polled_timestamps = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2885ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting raw compressed image data & saving to specific list (Images & TimeStamp)\n",
    "if __name__ == \"__main__\":\n",
    "    for msg in bag:\n",
    "            if  msg[0] == \"/delayed/evo/left_polled/image_rect/compressed\": #Replace with desired topic\n",
    "                timestamp = datetime.datetime.fromtimestamp(msg[2].to_sec()).strftime(\"%Y_%m_%d-%H_%M_%S\") #Extract and transform timestamp\n",
    "                Image_Rect_Left_Polled_timestamps.append(timestamp) #Replace list with corresponding topic list\n",
    "                raw_data = io.BytesIO(msg[1].data) #Extract raw image data from .bag file\n",
    "                image_data = imageio.v2.imread(raw_data)   \n",
    "                Image_Rect_Left_Polled.append(image_data) #Replace list with corresponding topic\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c197cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize & save compressed images from list\n",
    "path_image = './Images' #Path for new folder \"Images\"\n",
    "    \n",
    "#Check whether directory already exists\n",
    "if not os.path.exists(path_image):\n",
    "    os.mkdir(path_image)\n",
    "    print(\"Folder %s created!\" % path_image)\n",
    "else:\n",
    "    print(\"Folder %s already exists\" % path_image)\n",
    "        \n",
    "os.chdir(path_image)\n",
    "\n",
    "i = 0\n",
    "for img in Image_Rect_Left_Polled: #replace list with desired topic\n",
    "    plt.imshow(img, interpolation='nearest')\n",
    "    plt.axis(\"off\")\n",
    "    timestamp = Image_Rect_Left_Polled_timestamps[i]\n",
    "    plt.savefig(\"Image_Rect_Left_Polled \"+ str(timestamp) +\".jpg\") #Change name to corresponding topic\n",
    "    i += 1\n",
    "print(\"This picture was taken on: \" + timestamp)    \n",
    "os.chdir('../') #Change directory back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3709d212",
   "metadata": {},
   "source": [
    ">Un autre fichier dans le rosbag est de type geometry_msgs/PoseStamped. Il contient l'emplacement du rover ainsi que tous les horodatages. <br>\n",
    " Récupérons ces horodatages et formatons-les pour une meilleure lisibilité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70de50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get time stamps from all images and scans\n",
    "timestamps_total = []\n",
    "for msg in bag:\n",
    "    if  msg[0] == \"/delayed/trt_localization/pose\":\n",
    "        time = datetime.datetime.fromtimestamp(msg[2].to_sec()).strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "        timestamps_total.append(time)\n",
    "\n",
    "#Time stamps format updated and new csv file created \n",
    "location_csv = pd.read_csv(os.getcwd() + \"\\\\LEAD_delayed_2019-09-25-19-00-01-filtered\\\\delayed-trt_localization-pose.csv\") \n",
    "location_csv['TimeStamps'] = timestamps_total\n",
    "location_csv.to_csv('Localization_TimeStamp_Updated.csv') \n",
    "location_csv.iloc[:,-8:].head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa8aa99",
   "metadata": {},
   "source": [
    "*Un aperçu des 10 premières lignes de colonnes sélectionnées*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395522ed",
   "metadata": {},
   "source": [
    "***\n",
    "### Cartographie du chemin du Rover Juno\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf51a2",
   "metadata": {},
   "source": [
    "Notre prochaine étape est de cartographier le chemin du Rover Juno sur le Mars Yard. Nous allons d'abord extraire les positions du rover du fichier csv et le convertir en format latitude et longitude.\n",
    "> **Nous prenons les origines du Mars Yard comme (45.5182069858,-73.3939063839). Dans ce cas, nous projetons les positions x et y données, depuis l'origine.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting mars yard origin to utm\n",
    "mars_origin = utm.from_latlon(45.5182069858,-73.3939063839)\n",
    "print(mars_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca87d4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = geopandas.GeoDataFrame(\n",
    "    location_csv, geometry=geopandas.points_from_xy(location_csv[\"pose.position.x\"], location_csv[\"pose.position.y\"]))\n",
    "geo_df_list = [[point.xy[1][0], point.xy[0][0]] for point in gdf.geometry]\n",
    "\n",
    "i = 0\n",
    "for i in range(0,15951):\n",
    "    test_x = geo_df_list[i][0]+625438.2348290744\n",
    "    geo_df_list[i][0] = test_x\n",
    "    test_y = 5041773.785209548 - geo_df_list[i][1]\n",
    "    geo_df_list[i][1] = test_y\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3363c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting all rover positions to latitude & longitude and converting csv file to dictonary\n",
    "new_coord = []\n",
    "lat = []\n",
    "lon = []\n",
    "\n",
    "i = 0\n",
    "for i in range(0,15951):\n",
    "    coord = utm.to_latlon(geo_df_list[i][0], geo_df_list[i][1], 18, northern = True)\n",
    "    new_coord.append(coord)\n",
    "    lat.append(coord[0])\n",
    "    lon.append(coord[1])\n",
    "    i += 1\n",
    "\n",
    "location_csv['Lat'] = lat\n",
    "location_csv['Lon'] = lon\n",
    "location_csv.to_csv('Localization_Location_Updated.csv') \n",
    "location_csv\n",
    "\n",
    "with open('Localization_Location_Updated.csv') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    Timestamp_csv_dict = [row for row in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c431d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_csv.iloc[:,-3:].head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21acc1a9",
   "metadata": {},
   "source": [
    "*Latitude et longitude du rover avec l'horodatage respectif*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eaf60e",
   "metadata": {},
   "source": [
    ">Puisque toutes nos images ont un horodatage attaché, nous pouvons faire une référence croisée avec l'horodatage dans notre Timestamp_csv_dict et obtenir une position du rover au moment où l'image a été capturée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac443d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross references timestamps & returns image position (lat and lon)\n",
    "def get_position(timestamp):\n",
    "    for file in Timestamp_csv_dict:\n",
    "        if timestamp == file['TimeStamps']:\n",
    "            x_position = file['Lat']\n",
    "            y_position = file['Lon']\n",
    "            return (x_position, y_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215043a6",
   "metadata": {},
   "source": [
    ">Nous avons maintenant toutes les informations nécessaires pour tracer une carte du chemin du rover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dec368",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[45.5182069858,-73.3939063839], zoom_start=17)\n",
    "centred_polyline=folium.PolyLine(locations=new_coord,weight=5)\n",
    "m.add_child(centred_polyline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f23eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing Map\n",
    "img = imageio.imread(\"6-MAP.png\")\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e1062f",
   "metadata": {},
   "source": [
    ">Nous pouvons aussi ajouter des fenêtres contextuelles pour montrer où était le rover au moment où une image spécifique (ou liste d'images) a été prise. Nous utilisons toujours des images du sujet */delayed/evo/left_polled/image_rect/compressed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de0288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "path_images = os.getcwd() +\"\\\\Images\"\n",
    "for root, dirs, files in os.walk(path_images):\n",
    "    for file in files:\n",
    "            image_list.append(os.path.join(root,file)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da5f94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for image in image_list:\n",
    "    encoded = base64.b64encode(open(image,'rb').read())\n",
    "    name = (image[-46:-4]).replace(\"_\",\" \") #Retrieving image name \n",
    "    html = (str(name) + '<img src=\"data:image/png;base64,{}\">').format\n",
    "    iframe = IFrame(html(encoded.decode('UTF-8')), width=650, height=550)\n",
    "    popup = folium.Popup(iframe, max_width=650)\n",
    "    loc = get_position(image[-23:-4]) #Cross-referencing timestamp to get lat & lon\n",
    "    folium.Marker(location=[loc[0],loc[1]], tooltip=html, popup = popup, lazy = True,\n",
    "              icon=folium.Icon(color = 'blue')).add_to(m)\n",
    "    if len(image_list) > 7000:\n",
    "        i += 500\n",
    "    if len(image_list) > 1000 and len(image_list) < 7000:\n",
    "        i += 100\n",
    "    else:\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab2187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing pop-ups added to map\n",
    "img = imageio.imread(\"7-MAP_Images.png\")\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce47b8ea",
   "metadata": {},
   "source": [
    "*Chaque image contient son sujet et la date-heure à laquelle elle a été capturée.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf2a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imageio.imread(\"6-MAP.jpeg\")\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfdeb96",
   "metadata": {},
   "source": [
    "*Image qui apparaît après avoir cliqué sur une icône*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe2b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Close rosbag \n",
    "bag.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}